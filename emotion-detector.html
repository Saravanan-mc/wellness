<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Detection & Mental Health Bot</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            background-color: #f0f2f5;
            margin: 0;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }

        h1 {
            color: #333;
            margin-bottom: 20px;
        }

        #main-content {
            display: flex;
            flex-direction: row; /* Side-by-side layout */
            gap: 20px;
            align-items: flex-start; /* Align items to the top */
            max-width: 1200px; /* Adjust as needed */
            width: 100%;
        }

        #detection-column {
            display: flex;
            flex-direction: column;
            align-items: center;
            flex: 1; /* Takes available space */
        }

        #video-container {
            position: relative;
            margin-bottom: 20px;
            width: 600px;
            height: 450px;
            background: #000; /* Background for video area */
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
        }

        #video {
            border-radius: 8px;
            display: block; /* Prevents extra space below */
        }

        #canvas {
            position: absolute;
            top: 0;
            left: 0;
            border-radius: 8px;
        }

        #emotion-display {
            font-size: 22px;
            font-weight: bold;
            min-height: 30px;
            margin: 10px 0;
            padding: 8px 12px;
            border-radius: 5px;
            width: calc(100% - 24px); /* Adjust for padding */
            box-sizing: border-box;
        }

        .emotion-label { transition: background-color 0.3s, color 0.3s; }
        .happy { color: #27ae60; background-color: #e8f5e9; }
        .sad { color: #3498db; background-color: #e3f2fd; }
        .angry { color: #e74c3c; background-color: #ffebee; }
        .neutral { color: #7f8c8d; background-color: #f5f5f5; }
        .surprised { color: #f1c40f; background-color: #fffde7; }
        .disgusted { color: #8e44ad; background-color: #f3e5f5; }
        .fearful { color: #2c3e50; background-color: #eceff1; }
        .unknown { color: #333; background-color: #eee; }

        #controls button {
            background-color: #2c3e50;
            color: white;
            border: none;
            padding: 10px 20px;
            font-size: 15px;
            border-radius: 5px;
            cursor: pointer;
            margin: 5px;
            transition: all 0.3s;
        }
        #controls button:hover:not(:disabled) { background-color: #1a252f; transform: scale(1.05); }
        #controls button:disabled { background-color: #95a5a6; cursor: not-allowed; }

        #loader {
            display: none; margin: 15px auto; border: 4px solid #f3f3f3;
            border-top: 4px solid #3498db; border-radius: 50%;
            width: 40px; height: 40px; animation: spin 1s linear infinite;
        }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

        /* Chatbot Area Styles */
        #chatbot-column {
            flex: 0 0 350px; /* Fixed width for chatbot */
            display: flex;
            flex-direction: column;
            background-color: #ffffff;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
            padding: 15px;
            height: 550px; /* Max height, consistent with video area roughly */
        }

        #chatbot-column h2 {
            margin-top: 0;
            font-size: 18px;
            color: #333;
            border-bottom: 1px solid #eee;
            padding-bottom: 10px;
        }

        #chat-log {
            flex-grow: 1;
            overflow-y: auto;
            padding: 10px;
            border: 1px solid #e0e0e0;
            border-radius: 4px;
            margin-bottom: 10px;
            font-size: 14px;
            background-color: #f9f9f9;
        }

        .chat-message {
            margin-bottom: 8px;
            padding: 8px 12px;
            border-radius: 15px;
            max-width: 80%;
            word-wrap: break-word;
        }

        .user-message {
            background-color: #3498db;
            color: white;
            margin-left: auto;
            border-bottom-right-radius: 5px;
        }

        .bot-message {
            background-color: #e9e9eb;
            color: #333;
            margin-right: auto;
            border-bottom-left-radius: 5px;
        }
         .bot-message.empathy-message { /* Special style for initial empathy */
            background-color: #d1ecf1;
            color: #0c5460;
            border: 1px solid #bee5eb;
        }


        #chat-input-area {
            display: flex;
            gap: 10px;
        }

        #chat-input {
            flex-grow: 1;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-size: 14px;
        }

        #send-chat-btn {
            padding: 10px 15px;
            background-color: #27ae60;
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
        }
        #send-chat-btn:hover { background-color: #219d52; }
        #send-chat-btn:disabled { background-color: #95a5a6; }

           /* Custom styles for Inter font and general body styling */
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f8fafc; /* Light blue-gray background */
            color: #334155; /* Dark slate gray text */
        }
        /* Smooth scrolling for anchor links */
        html {
            scroll-behavior: smooth;
        }

    </style>
</head>
<body>
    <h1>Emotion Detection & Mental Health Bot</h1>

    <div id="main-content">
        <div id="detection-column">
            <div id="video-container">
                <video id="video" width="600" height="450" autoplay muted playsinline></video>
                <canvas id="canvas"></canvas>
            </div>
            <div id="emotion-display" class="neutral">Loading models... Please wait.</div>
            <div id="loader"></div>
            <div id="controls">
                <button id="startBtn" disabled>Start Detection</button>
                <button id="stopBtn" disabled>Stop Detection</button>
            </div>
        </div>

        <div id="chatbot-column">
            <h2>Mental Health Support Bot</h2>
            <div id="chat-log">
                <div class="chat-message bot-message">Hello! I'm here to offer some support based on how you might be feeling.</div>
            </div>
            <div id="chat-input-area">
                <input type="text" id="chat-input" placeholder="Type your message...">
                <button id="send-chat-btn">Send</button>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <script>
        // --- Your existing JavaScript will go here, with modifications ---
        // DOM elements
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const emotionDisplay = document.getElementById('emotion-display');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const loader = document.getElementById('loader');

        // Chatbot DOM elements
        const chatLog = document.getElementById('chat-log');
        const chatInput = document.getElementById('chat-input');
        const sendChatBtn = document.getElementById('send-chat-btn');

        let detectionIntervalId;
        let stream;

        // --- Gemini API Configuration ---
        // !!! IMPORTANT: For local testing ONLY. DO NOT deploy with client-side keys.
        const GEMINI_API_KEY = 'YOUR_GEMINI_API_KEY'; // Replace with your actual Gemini Flash Key (AIza...)
        const GEMINI_MODEL = 'gemini-1.5-flash-latest'; // Or 'gemini-pro' if you have a key for it

        // --- Emotion Stability Logic ---
        let lastStableEmotion = null;
        let currentEmotionBuffer = []; // Store recent emotions
        const EMOTION_BUFFER_SIZE = 15; // Number of frames to consider for stability (adjust for ~5s)
                                        // e.g., if detection is ~3-4 FPS, 15 frames is ~4-5 seconds.
        const STABILITY_THRESHOLD = 0.7; // 70% of buffer must be the same emotion
        let chatbotCooldown = false; // To prevent rapid triggering for the same emotion
        const CHATBOT_COOLDOWN_PERIOD = 30000; // 30 seconds

        function showLoader(show) {
            loader.style.display = show ? 'block' : 'none';
        }

        async function loadModels() {
            showLoader(true);
            emotionDisplay.textContent = 'Loading models... Please wait.';
            emotionDisplay.className = 'emotion-label unknown';
            try {
                const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL),
                    faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL),
                    faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL)
                ]);
                console.log('Face-API Models loaded successfully');
                emotionDisplay.textContent = 'Models loaded. Ready to start detection.';
                addMessageToChatLog("Face detection models loaded. I'm ready when you are!", 'bot');
                startBtn.disabled = false;
            } catch (error) {
                console.error('Error loading models:', error);
                emotionDisplay.textContent = 'Error loading models. Please refresh.';
                emotionDisplay.className = 'emotion-label angry';
                addMessageToChatLog("Sorry, I couldn't load the emotion detection models. Please try refreshing the page.", 'bot');
            } finally {
                showLoader(false);
            }
        }

        async function startVideo() {
            // ... (startVideo function from previous good example - largely unchanged)
            if (stream) {
                video.play();
                startBtn.textContent = 'Detection Active';
                startBtn.disabled = true;
                stopBtn.disabled = false;
                detectEmotions();
                return;
            }

            try {
                stream = await navigator.mediaDevices.getUserMedia({ video: { width: 600, height: 450 } });
                video.srcObject = stream;
                video.setAttribute('playsinline', '');

                emotionDisplay.textContent = 'Initializing camera...';
                emotionDisplay.className = 'emotion-label neutral';

                video.onplay = () => {
                    console.log("Video playing");
                    canvas.width = video.width;
                    canvas.height = video.height;
                    faceapi.matchDimensions(canvas, { width: video.width, height: video.height });
                    
                    startBtn.textContent = 'Detection Active';
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                    emotionDisplay.textContent = 'Detecting emotions...';
                    detectEmotions(); 
                };

            } catch (error) {
                console.error('Error accessing camera:', error);
                emotionDisplay.textContent = 'Camera access denied or error.';
                emotionDisplay.className = 'emotion-label angry';
                addMessageToChatLog("I can't seem to access your camera. Please check permissions.", 'bot');
                startBtn.disabled = false;
                stopBtn.disabled = true;
            }
        }

        function stopDetection() {
            // ... (stopDetection function from previous good example - largely unchanged)
            if (detectionIntervalId) {
                cancelAnimationFrame(detectionIntervalId);
                detectionIntervalId = null;
            }
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                video.srcObject = null; 
                stream = null; 
            }
            const context = canvas.getContext('2d');
            context.clearRect(0, 0, canvas.width, canvas.height);
            emotionDisplay.textContent = 'Detection stopped. Click Start to resume.';
            emotionDisplay.className = 'emotion-label neutral';
            startBtn.textContent = 'Start Detection';
            startBtn.disabled = false;
            stopBtn.disabled = true;
            currentEmotionBuffer = []; // Clear buffer on stop
            lastStableEmotion = null;
            console.log("Detection stopped and camera released.");
        }

        async function detectEmotions() {
            if (!video.srcObject || video.paused || video.ended) {
                if (startBtn.disabled) stopDetection();
                return;
            }

            try {
                const detection = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceLandmarks()
                    .withFaceExpressions();

                const displaySize = { width: video.width, height: video.height };
                const context = canvas.getContext('2d');
                context.clearRect(0, 0, canvas.width, canvas.height);

                if (detection) {
                    const resizedDetection = faceapi.resizeResults(detection, displaySize);
                    faceapi.draw.drawDetections(canvas, resizedDetection);
                    // faceapi.draw.drawFaceLandmarks(canvas, resizedDetection); // Optional: can be noisy
                    faceapi.draw.drawFaceExpressions(canvas, resizedDetection);

                    const expressions = resizedDetection.expressions;
                    let dominantEmotion = 'neutral';
                    let maxConfidence = 0;

                    for (const [emotion, confidence] of Object.entries(expressions)) {
                        if (confidence > maxConfidence) {
                            maxConfidence = confidence;
                            dominantEmotion = emotion;
                        }
                    }

                    if (maxConfidence > 0.5) {
                        emotionDisplay.textContent = `Detected: ${dominantEmotion} (${Math.round(maxConfidence * 100)}%)`;
                        emotionDisplay.className = `emotion-label ${dominantEmotion}`;
                        
                        // Emotion stability check
                        currentEmotionBuffer.push(dominantEmotion);
                        if (currentEmotionBuffer.length > EMOTION_BUFFER_SIZE) {
                            currentEmotionBuffer.shift(); // Keep buffer size fixed
                        }

                        if (currentEmotionBuffer.length === EMOTION_BUFFER_SIZE) {
                            const counts = currentEmotionBuffer.reduce((acc, val) => {
                                acc[val] = (acc[val] || 0) + 1;
                                return acc;
                            }, {});
                            
                            const mostFrequentEmotionInBufer = Object.keys(counts).reduce((a, b) => counts[a] > counts[b] ? a : b);
                            
                            if (counts[mostFrequentEmotionInBufer] / EMOTION_BUFFER_SIZE >= STABILITY_THRESHOLD) {
                                if (mostFrequentEmotionInBufer !== lastStableEmotion && !chatbotCooldown) {
                                    lastStableEmotion = mostFrequentEmotionInBufer;
                                    console.log(`Stable emotion detected: ${lastStableEmotion}`);
                                    triggerChatbotForEmotion(lastStableEmotion);
                                    chatbotCooldown = true;
                                    setTimeout(() => {
                                        chatbotCooldown = false;
                                        lastStableEmotion = null; // Allow re-triggering after cooldown if emotion persists or changes
                                    }, CHATBOT_COOLDOWN_PERIOD);
                                }
                            }
                        }

                    } else {
                        emotionDisplay.textContent = "Expression unclear or neutral";
                        emotionDisplay.className = "emotion-label neutral";
                        // Potentially clear buffer if expression is too unclear, or let it phase out
                        // currentEmotionBuffer.push('neutral'); // Or handle differently
                    }
                } else {
                    emotionDisplay.textContent = "No face detected.";
                    emotionDisplay.className = "emotion-label unknown";
                    currentEmotionBuffer = []; // Clear buffer if no face
                    lastStableEmotion = null;
                }
            } catch (error) {
                console.error("Error during detection:", error);
            }

            if (startBtn.disabled) {
                 detectionIntervalId = requestAnimationFrame(detectEmotions);
            }
        }

        // --- Chatbot Functions ---
        function addMessageToChatLog(message, sender, isEmpathy = false) {
            const messageDiv = document.createElement('div');
            messageDiv.classList.add('chat-message');
            if (sender === 'user') {
                messageDiv.classList.add('user-message');
            } else {
                messageDiv.classList.add('bot-message');
                if (isEmpathy) {
                     messageDiv.classList.add('empathy-message');
                }
            }
            messageDiv.textContent = message; // Use textContent for security against XSS
            chatLog.appendChild(messageDiv);
            chatLog.scrollTop = chatLog.scrollHeight; // Auto-scroll to bottom
        }

        async function callGeminiAPI(promptText) {
            if (!GEMINI_API_KEY || GEMINI_API_KEY === 'AIzaSyAwMyOYTo7xDdXMDF7v1bpfSQa1t5XkQWk') {
                console.error("Gemini API Key not configured.");
                return "I'm not configured correctly to respond right now. (API Key missing)";
            }
            sendChatBtn.disabled = true;
            chatInput.disabled = true;

            const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/${GEMINI_MODEL}:generateContent?key=${GEMINI_API_KEY}`;

            const requestBody = {
                contents: [{
                    parts: [{ text: promptText }]
                }],
                // Optional: Add safetySettings, generationConfig if needed
                // "generationConfig": {
                //   "temperature": 0.7,
                //   "maxOutputTokens": 250
                // }
            };

            try {
                const response = await fetch(API_URL, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(requestBody)
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    console.error('Gemini API Error:', errorData);
                    throw new Error(`API Error: ${response.status} ${response.statusText} - ${errorData.error?.message || 'Unknown error'}`);
                }

                const data = await response.json();
                // console.log("Gemini API Response:", data);

                if (data.candidates && data.candidates.length > 0 &&
                    data.candidates[0].content && data.candidates[0].content.parts &&
                    data.candidates[0].content.parts.length > 0) {
                    return data.candidates[0].content.parts[0].text.trim();
                } else {
                    console.warn("No valid content in Gemini response:", data);
                    return "I'm having a little trouble forming a response right now.";
                }
            } catch (error) {
                console.error('Error calling Gemini API:', error);
                return `Sorry, I encountered an issue: ${error.message.substring(0,100)}`;
            } finally {
                sendChatBtn.disabled = false;
                chatInput.disabled = false;
                chatInput.focus();
            }
        }

        async function triggerChatbotForEmotion(emotion) {
            console.log(`Chatbot triggered for emotion: ${emotion}`);
            let prompt;
            switch (emotion) {
                case 'happy':
                    prompt = "The user seems to be feeling happy. Offer a short, uplifting message or a gentle positive affirmation. Keep it concise.";
                    break;
                case 'sad':
                    prompt = "The user seems to be feeling sad. Offer a brief, empathetic message of support and understanding. Suggest a very simple, gentle coping thought. Keep it concise.";
                    break;
                case 'angry':
                    prompt = "The user seems to be feeling angry. Offer a very brief, calming message. Acknowledge the feeling without judgment and perhaps suggest taking a moment to breathe. Keep it concise.";
                    break;
                case 'surprised':
                    prompt = "The user seems to be surprised. Offer a lighthearted, curious, or reassuring brief message. Keep it concise.";
                    break;
                case 'neutral':
                     prompt = "The user seems to have a neutral expression. Offer a calm, gentle check-in message or a simple mindfulness reminder. Keep it concise. For example: 'Feeling neutral can be a good moment for a calm breath.'";
                    break;
                case 'fearful':
                    prompt = "The user seems to be feeling fearful or anxious. Offer a brief, reassuring and calming message. Suggest a simple grounding technique like focusing on their breath. Keep it concise.";
                    break;
                case 'disgusted':
                    prompt = "The user seems to be feeling disgusted. Acknowledge this strong emotion briefly and offer a neutral, grounding thought. Keep it concise.";
                    break;
                default:
                    prompt = `The user is showing an emotion: ${emotion}. Offer a general supportive and brief message.`;
            }
            
            // Add context for the chatbot's persona
            const fullPrompt = `You are a friendly and empathetic AI assistant designed to provide brief, supportive mental wellness messages. Do not ask questions like "How can I help?". Respond directly to the implied feeling. User's detected emotion: ${emotion}. Your task based on this: ${prompt}`;

            addMessageToChatLog(`I sense you might be feeling ${emotion}. Thinking...`, 'bot', true);
            const botResponse = await callGeminiAPI(fullPrompt);
            addMessageToChatLog(botResponse, 'bot', true); // Mark initial empathetic message
        }

        async function handleUserChat() {
            const userMessage = chatInput.value.trim();
            if (!userMessage) return;

            addMessageToChatLog(userMessage, 'user');
            chatInput.value = '';

            // More sophisticated prompt for follow-up:
            // You might want to include chat history for better context in a real app.
            // For this example, we'll keep it simple.
            const followUpPrompt = `You are a friendly and empathetic AI assistant. The user said: "${userMessage}". Provide a supportive and helpful response. If the user's message is short or unclear, you can offer general encouragement or ask a gentle open-ended question to understand more, like 'Tell me a bit more about that if you feel comfortable.'`;
            
            addMessageToChatLog("Thinking...", 'bot'); // Placeholder
            const botResponse = await callGeminiAPI(followUpPrompt);
            addMessageToChatLog(botResponse, 'bot');
        }


        // Initialize the app
        async function init() {
            await loadModels();
            startBtn.addEventListener('click', startVideo);
            stopBtn.addEventListener('click', stopDetection);
            sendChatBtn.addEventListener('click', handleUserChat);
            chatInput.addEventListener('keypress', (event) => {
                if (event.key === 'Enter') {
                    handleUserChat();
                }
            });

            video.addEventListener('pause', () => { if (startBtn.disabled) { /* Loop will stop */ } });
            video.addEventListener('ended', () => { if (startBtn.disabled) stopDetection(); });
        }

        init();

    </script>
</body>
</html>